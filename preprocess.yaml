name: Preprocess Server Machine Dataset
description: Preprocesses dataset from load_dataset brick and prepares output paths for training, testing, and anomaly detection.

inputs:
  - name: raw_dataset_pth
    type: String
    description: Path to raw dataset output from load_dataset brick.
  - name: output_dir
    type: String
    description: Directory to store processed datasets.
  - name: train_pth
    type: String
    description: Path to save processed training set.
  - name: test_pth
    type: String
    description: Path to save processed testing set.
  - name: anomaly_pth
    type: String
    description: Path to save processed anomaly set.

outputs:
  - name: train_out
    type: String
    description: Processed training dataset path.
  - name: test_out
    type: String
    description: Processed testing dataset path.
  - name: anomaly_out
    type: String
    description: Processed anomaly dataset path.

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        set -e
        # Install dependencies
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet pandas numpy --user

        # Run Python script
        python3 -u - <<'PYCODE'
        import argparse
        import pandas as pd
        import os

        parser = argparse.ArgumentParser()
        parser.add_argument('--raw_dataset_pth', type=str, required=True)
        parser.add_argument('--output_dir', type=str, required=True)
        parser.add_argument('--train_pth', type=str, required=True)
        parser.add_argument('--test_pth', type=str, required=True)
        parser.add_argument('--anomaly_pth', type=str, required=True)
        parser.add_argument('--train_out', type=str, required=True)
        parser.add_argument('--test_out', type=str, required=True)
        parser.add_argument('--anomaly_out', type=str, required=True)
        args = parser.parse_args()

        os.makedirs(args.output_dir, exist_ok=True)

        df = pd.read_csv(args.raw_dataset_pth)

        # Example split (replace with actual logic)
        train_df = df.sample(frac=0.7, random_state=42)
        test_df = df.drop(train_df.index)
        anomaly_df = df[df['label'] == 'anomaly'] if 'label' in df.columns else pd.DataFrame()

        train_df.to_csv(args.train_out, index=False)
        test_df.to_csv(args.test_out, index=False)
        anomaly_df.to_csv(args.anomaly_out, index=False)

        print(f"[INFO] Using input train_pth = {args.train_pth}")
        print(f"[INFO] Using input test_pth = {args.test_pth}")
        print(f"[INFO] Using input anomaly_pth = {args.anomaly_pth}")

        print(f"[SUCCESS] Train saved to: {args.train_out}")
        print(f"[SUCCESS] Test saved to: {args.test_out}")
        print(f"[SUCCESS] Anomaly saved to: {args.anomaly_out}")
        PYCODE
    args:
      - --raw_dataset_pth
      - {inputValue: raw_dataset_pth}
      - --output_dir
      - {inputValue: output_dir}
      - --train_pth
      - {inputValue: train_pth}
      - --test_pth
      - {inputValue: test_pth}
      - --anomaly_pth
      - {inputValue: anomaly_pth}
      - --train_out
      - {outputPath: train_out}
      - --test_out
      - {outputPath: test_out}
      - --anomaly_out
      - {outputPath: anomaly_out}
