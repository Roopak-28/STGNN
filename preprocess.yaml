name: Preprocess Server Machine Dataset
description: Preprocesses dataset from load_dataset brick and prepares output paths for training, testing, and anomaly detection.

inputs:
  - name: raw_dataset_pth
    type: Path
    description: Path to raw dataset output from load_dataset brick.
  - name: output_dir
    type: String
    description: Directory to store processed datasets.
  - name: train_pth
    type: String
    description: Path to save processed training set.
  - name: test_pth
    type: String
    description: Path to save processed testing set.
  - name: anomaly_pth
    type: String
    description: Path to save processed anomaly set.

outputs:
  - name: train_out
    type: Path
    description: Processed training dataset path.
  - name: test_out
    type: Path
    description: Processed testing dataset path.
  - name: anomaly_out
    type: Path
    description: Processed anomaly dataset path.

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        set -e
        # Install dependencies
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet pandas numpy --user
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import pandas as pd
        import os

        parser = argparse.ArgumentParser()
        parser.add_argument('--raw_dataset_pth', type=str, required=True)
        parser.add_argument('--output_dir', type=str, required=True)
        parser.add_argument('--train_pth', type=str, required=True)
        parser.add_argument('--test_pth', type=str, required=True)
        parser.add_argument('--anomaly_pth', type=str, required=True)
        parser.add_argument('--train_out', type=str, required=True)
        parser.add_argument('--test_out', type=str, required=True)
        parser.add_argument('--anomaly_out', type=str, required=True)
        args = parser.parse_args()

        os.makedirs(args.output_dir, exist_ok=True)
        os.makedirs(os.path.dirname(args.train_pth), exist_ok=True)
        os.makedirs(os.path.dirname(args.test_pth), exist_ok=True)
        os.makedirs(os.path.dirname(args.anomaly_pth), exist_ok=True)

        # Read actual dataset path from the path-only file
        with open(args.raw_dataset_pth, "r") as f:
            real_dataset_path = f.read().strip()
        print(f"[INFO] Resolved raw dataset path = {real_dataset_path}")

        # Handle case: directory with multiple files vs single file
        if os.path.isdir(real_dataset_path):
            all_files = [os.path.join(real_dataset_path, f) 
                         for f in os.listdir(real_dataset_path) 
                         if f.endswith(".csv") or f.endswith(".txt")]
            if not all_files:
                raise FileNotFoundError(f"No .csv/.txt files found in directory {real_dataset_path}")
            df_list = [pd.read_csv(f, header=None) for f in sorted(all_files)]
            df = pd.concat(df_list, ignore_index=True)
        else:
            df = pd.read_csv(real_dataset_path)

        # Example split (replace with your actual logic)
        train_df = df.sample(frac=0.7, random_state=42)
        test_df = df.drop(train_df.index)
        anomaly_df = df[df.iloc[:, -1] == 1] if df.shape[1] > 1 else pd.DataFrame()

        # Save processed datasets
        train_df.to_csv(args.train_pth, index=False)
        test_df.to_csv(args.test_pth, index=False)
        anomaly_df.to_csv(args.anomaly_pth, index=False)

        # Emit output artifact paths
        with open(args.train_out, "w") as f: f.write(args.train_pth)
        with open(args.test_out, "w") as f: f.write(args.test_pth)
        with open(args.anomaly_out, "w") as f: f.write(args.anomaly_pth)

        print(f"[SUCCESS] Train saved to: {args.train_pth}")
        print(f"[SUCCESS] Test saved to: {args.test_pth}")
        print(f"[SUCCESS] Anomaly saved to: {args.anomaly_pth}")
    args:
      - --raw_dataset_pth
      - {inputPath: raw_dataset_pth}
      - --output_dir
      - {inputValue: output_dir}
      - --train_pth
      - {inputValue: train_pth}
      - --test_pth
      - {inputValue: test_pth}
      - --anomaly_pth
      - {inputValue: anomaly_pth}
      - --train_out
      - {outputPath: train_out}
      - --test_out
      - {outputPath: test_out}
      - --anomaly_out
      - {outputPath: anomaly_out}
