name: Preprocess Server Machine Dataset
description: Preprocesses SMD dataset from load_dataset brick and prepares train, test, and anomaly CSVs.

inputs:
  - name: train_csv
    type: Path
    description: File containing path string to training dataset directory.
  - name: test_csv
    type: Path
    description: File containing path string to testing dataset directory.
  - name: labels_csv
    type: Path
    description: File containing path string to anomaly labels directory.
  - name: output_dir
    type: String
    description: Directory to store processed datasets.
  - name: train_pth
    type: String
    description: Path to save processed training set.
  - name: test_pth
    type: String
    description: Path to save processed testing set.
  - name: anomaly_pth
    type: String
    description: Path to save processed anomaly set.

outputs:
  - name: train_out
    type: Path
    description: Processed training dataset path.
  - name: test_out
    type: Path
    description: Processed testing dataset path.
  - name: anomaly_out
    type: Path
    description: Processed anomaly dataset path.

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        set -e
        apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet pandas numpy --user
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse, os, pandas as pd, subprocess

        parser = argparse.ArgumentParser()
        parser.add_argument('--train_csv', type=str, required=True)
        parser.add_argument('--test_csv', type=str, required=True)
        parser.add_argument('--labels_csv', type=str, required=True)
        parser.add_argument('--output_dir', type=str, required=True)
        parser.add_argument('--train_pth', type=str, required=True)
        parser.add_argument('--test_pth', type=str, required=True)
        parser.add_argument('--anomaly_pth', type=str, required=True)
        parser.add_argument('--train_out', type=str, required=True)
        parser.add_argument('--test_out', type=str, required=True)
        parser.add_argument('--anomaly_out', type=str, required=True)
        args = parser.parse_args()

        os.makedirs(args.output_dir, exist_ok=True)

        # Read paths from upstream step
        with open(args.train_csv, "r") as f: train_path = f.read().strip()
        with open(args.test_csv, "r") as f: test_path = f.read().strip()
        with open(args.labels_csv, "r") as f: labels_path = f.read().strip()

        print(f"[INFO] Train dir (from file): {train_path}")
        print(f"[INFO] Test dir (from file): {test_path}")
        print(f"[INFO] Labels dir (from file): {labels_path}")

        # Ensure OmniAnomaly repo exists in this pod
        if not os.path.exists("/tmp/omni/data/SMD"):
            print("[INFO] Cloning OmniAnomaly repo...")
            subprocess.run("git clone https://github.com/NetManAIOps/OmniAnomaly /tmp/omni", shell=True, check=True)

        # Helper to load directory of CSV/TXT files
        def load_dir(path):
            files = [os.path.join(path, f) for f in sorted(os.listdir(path)) if f.endswith('.txt') or f.endswith('.csv')]
            if not files:
                raise FileNotFoundError(f"No data files found in {path}")
            return pd.concat([pd.read_csv(f, header=None) for f in files], ignore_index=True)

        train_df = load_dir(train_path)
        test_df = load_dir(test_path)
        anomaly_df = load_dir(labels_path)

        # Save processed datasets
        train_df.to_csv(args.train_pth, index=False)
        test_df.to_csv(args.test_pth, index=False)
        anomaly_df.to_csv(args.anomaly_pth, index=False)

        # Emit Kubeflow artifact paths
        with open(args.train_out, "w") as f: f.write(args.train_pth)
        with open(args.test_out, "w") as f: f.write(args.test_pth)
        with open(args.anomaly_out, "w") as f: f.write(args.anomaly_pth)

        print(f"[SUCCESS] Train saved to: {args.train_pth}")
        print(f"[SUCCESS] Test saved to: {args.test_pth}")
        print(f"[SUCCESS] Anomaly saved to: {args.anomaly_pth}")

    args:
      - --train_csv
      - {inputPath: train_csv}
      - --test_csv
      - {inputPath: test_csv}
      - --labels_csv
      - {inputPath: labels_csv}
      - --output_dir
      - {inputValue: output_dir}
      - --train_pth
      - {inputValue: train_pth}
      - --test_pth
      - {inputValue: test_pth}
      - --anomaly_pth
      - {inputValue: anomaly_pth}
      - --train_out
      - {outputPath: train_out}
      - --test_out
      - {outputPath: test_out}
      - --anomaly_out
      - {outputPath: anomaly_out}
