name: Load Server Dataset
description: Loads dataset from the server machine and saves it as a PyTorch .pt file.

inputs:
  - name: data
    type: String
    description: Path to dataset on the server machine (e.g., /mnt/data/train.csv)

  - name: batch_size
    type: Integer
    description: Number of samples per batch
    default: 32

  - name: device
    type: String
    description: Device to use for training (cpu, cuda, cuda:0, etc.)
    default: cuda:0

  - name: scaling_required
    type: Boolean
    description: Whether to apply feature scaling to the dataset
    default: true

outputs:
  - name: outputpath1
    type: String
    description: Path to saved dataset file (.pt)

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        # Install dependencies
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet torch torchvision torchaudio --user
        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet pandas --user

        # Run Python script
        python3 -u - <<'PYCODE'
        import argparse
        import os
        import torch
        from my_dataset_module import load_dataset  # Replace with actual module

        parser = argparse.ArgumentParser()
        parser.add_argument('--data', type=str, required=True)
        parser.add_argument('--batch_size', type=int, required=True)
        parser.add_argument('--device', type=str, required=True)
        parser.add_argument('--scaling_required', type=bool, required=True)
        parser.add_argument('--outputpath1', type=str, required=True)
        args = parser.parse_args()

        print(f"[INFO] Loading dataset from: {args.data}")
        device = torch.device(args.device)

        dataloader = load_dataset(
            args.data,
            args.batch_size,
            args.batch_size,
            args.batch_size,
            args.scaling_required
        )
        scaler = dataloader['scaler']

        # Ensure the directory exists
        os.makedirs(os.path.dirname(args.outputpath1), exist_ok=True)

        # Save the entire dataloader and scaler for later use
        torch.save({'dataloader': dataloader, 'scaler': scaler}, args.outputpath1)
        print(f"[SUCCESS] Saved dataset and scaler to {args.outputpath1}")
        PYCODE
    args:
      - --data
      - { inputValue: data }
      - --batch_size
      - { inputValue: batch_size }
      - --device
      - { inputValue: device }
      - --scaling_required
      - { inputValue: scaling_required }
      - --outputpath1
      - { outputPath: outputpath1 }
